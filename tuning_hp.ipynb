{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from matplotlib import style\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import itertools\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import pandas as pd\n",
    "from scipy.special import comb\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectPercentile, GenericUnivariateSelect\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/Users/yash_/Documents/project/\"\n",
    "CATEGORIES = [\"Segmented_Laugh\", \"Segmented_NonLaugh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createcombinations(n):\n",
    "    elements = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "    a = list(itertools.combinations(elements, n))\n",
    "    a = np.asarray(a).astype(int)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(t_frame, t_shift, n_mfccs, component, training_data, n_features):\n",
    "    count=0\n",
    "    error_count = 0\n",
    "    laugh_counter = 0\n",
    "    nonlaugh_counter = 0\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for aud in os.listdir(path):\n",
    "            if aud == '.DS_Store':\n",
    "                continue\n",
    "            \n",
    "            aud_array , sr = librosa.load(os.path.join(path,aud), sr=None)\n",
    "            count+=1\n",
    "\n",
    "            mfccs = []\n",
    "            \n",
    "            try:\n",
    "                mfcc = (librosa.feature.mfcc(aud_array, sr=sr,  n_mfcc=20,  win_length = int(sr*t_frame), hop_length = int(sr*t_shift))) \n",
    "                mfcc_temp = mfcc[component,:]\n",
    "                #mfcc_temp = librosa.feature.delta(mfcc_temp)\n",
    "                #mfcc_temp = librosa.feature.delta(mfcc_temp)\n",
    "                mean_mfccs = np.mean(np.asarray(mfcc_temp),axis = 1)\n",
    "                #var_mfccs = np.var(np.asarray(mfcc_temp), axis = 1)\n",
    "                \n",
    "                mfccs.append(mean_mfccs)\n",
    "                #mfccs.append(var_mfccs)\n",
    "                mfccs = np.asarray(mfccs).reshape(n_mfccs*n_features,1)\n",
    "                \n",
    "                training_data.append([mfccs.reshape(-1,1), class_num])\n",
    "                if category == 'Segmented_Laugh':\n",
    "                    laugh_counter +=1\n",
    "                else:\n",
    "                    nonlaugh_counter += 1\n",
    "                    if nonlaugh_counter >= laugh_counter:\n",
    "                        break\n",
    "\n",
    "            except ValueError:\n",
    "                pass\n",
    "            \n",
    "    return laugh_counter, nonlaugh_counter\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X,n_mfcc):\n",
    "    for i in range(n_mfcc):\n",
    "        X[:,i] = X[:,i]/(np.mean(X[:,i]))\n",
    "        \n",
    "\n",
    "    #X[:,1] = np.square(X[:,1])\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "t_frame = 0.025\n",
    "t_shift = 0.01\n",
    "n_mfcc = 20\n",
    "component = createcombinations(n_mfcc)\n",
    "\n",
    "for components in component:\n",
    "    training_data = []\n",
    "    laugh, nonlaugh = create_training_data(t_frame, t_shift, n_mfcc, components, training_data, n_features)\n",
    "    print(laugh, nonlaugh)\n",
    "    \n",
    "random.shuffle(training_data) \n",
    "X = []\n",
    "Y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "        \n",
    "X = np.array(X).reshape(-1,n_mfcc*n_features)\n",
    "Y = np.array(Y)\n",
    "X = scaling(X,n_mfcc)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFS ( if forward = True ) and SBS ( if forward = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we will try knn, Gmm, Rf and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2) # ml_algo used = knn\n",
    "sfs1 = SFS(knn, \n",
    "           k_features=3, \n",
    "           forward=True, # if forward = True then SFS otherwise SBS\n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy'\n",
    "           )\n",
    "\n",
    "pipe = Pipeline([('sfs', sfs1), \n",
    "                 ('knn', knn)])\n",
    "\n",
    "param_grid = [\n",
    "  {'sfs__k_features': [2,4,6,8,10],\n",
    "   'sfs__estimator__n_neighbors': [1, 5, 10,15,17,19]}\n",
    "  ] # dict. for tuning inside and outside hyperparameters i.e. no. of k_features and no. of neighbors( for knn ) \n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=5,\n",
    "                  iid=True,\n",
    "                  refit=False)\n",
    "\n",
    "# run gridearch\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_0 = []\n",
    "index_1 = []\n",
    "result = []\n",
    "for i in range(len(gs.cv_results_['params'])):\n",
    "    dic = gs.cv_results_['params'][i].values()\n",
    "    lis = list(dic)\n",
    "    index_0.append(int(lis[0]))\n",
    "    result.append(float(gs.cv_results_['mean_test_score'][i]))\n",
    "    index_1.append(int(lis[1]))\n",
    "\n",
    "    \n",
    "dataframe  = pd.DataFrame(columns=['sfs__estimator__n_neighbors','sfs__k_features','Test Accuracy'])\n",
    "dataframe['sfs__estimator__n_neighbors'] = np.array(index_0) \n",
    "#change the name of 0th column for different algos. i.e ex. for RF name = 'sfs__estimator__n_trees'\n",
    "dataframe['sfs__k_features'] = np.array(index_1)\n",
    "dataframe['Test Accuracy'] = np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#showing the parameters with best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(**gs.best_params_).fit(X_train, y_train)\n",
    "print('Best features:', pipe.steps[0][1].k_feature_idx_)\n",
    "\n",
    "print('Best score:', gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the dataframe into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('/Users/yash_/Documents/project/file1.csv')\n",
    "# change the address accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot for a particular k_feature (run_after_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('dark_background')\n",
    "fig1 = plot_sfs(sfs1.get_metric_dict(), kind='std_dev')\n",
    "plt.title('Sequential Backward Selection (w. StdDev)')\n",
    "#plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
