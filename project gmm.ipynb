{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import sklearn\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"data\"\n",
    "CATEGORIES = [\"Segmented_Laugh\", \"Segmented_NonLaugh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "def create_training_data():\n",
    "    count=0\n",
    "    error_count = 0\n",
    "    #Enter time in seconds\n",
    "    t_window = 1\n",
    "    t_frame = 0.025\n",
    "    t_shift = 0.01\n",
    "    n_mfccs = n_mfcc\n",
    "    laugh_counter = 0\n",
    "    nonlaugh_counter = 0\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        print('New Folder')\n",
    "\n",
    "        for aud in os.listdir(path):\n",
    "            if aud == '.DS_Store':\n",
    "                continue\n",
    "            \n",
    "            aud_array , sr = librosa.load(os.path.join(path,aud), sr=None)\n",
    "            count+=1\n",
    "\n",
    "            mfccs = []\n",
    "            \n",
    "            try:\n",
    "                mfcc_temp = (librosa.feature.mfcc(aud_array, sr=sr,  n_mfcc=n_mfccs,  win_length = int(sr*t_frame), hop_length = int(sr*t_shift))) \n",
    "                mfcc_delta = librosa.feature.delta(mfcc_temp)\n",
    "                \n",
    "                mean_mfccs = np.mean(np.asarray(mfcc_temp),axis = 1)\n",
    "                var_mfccs = np.var(np.asarray(mfcc_temp), axis = 1)\n",
    "                std_deltamfccs = np.std(np.asarray(mfcc_delta), axis = 1)\n",
    "                \n",
    "                mfccs.append(mean_mfccs)\n",
    "                mfccs.append(var_mfccs)\n",
    "                mfccs.append(std_deltamfccs)\n",
    "                mfccs = np.asarray(mfccs).reshape(n_mfccs*3,1)\n",
    "                training_data.append([mfccs.reshape(-1,1), class_num])\n",
    "                if category == 'Segmented_Laugh':\n",
    "                    laugh_counter +=1\n",
    "                else:\n",
    "                    nonlaugh_counter += 1\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Oops!  That was no valid number.  Try again...\")\n",
    "        \n",
    "    print(laugh_counter, nonlaugh_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Folder\n",
      "New Folder\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "616 604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_training_data()\n",
    "data = np.array(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc array | class\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1220, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = []\n",
    "Y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "    \n",
    "X = np.array(X).reshape(-1,n_mfcc*3)\n",
    "#-1 corresponds to how many features we have\n",
    "Y = np.array(Y)\n",
    "#X = X/250\n",
    "#print(X.shape)\n",
    "#print(Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.7, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=2, n_init=1, precisions_init=None,\n",
       "                random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "                verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[372  53]\n",
      " [192 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.75       425\n",
      "           1       0.82      0.55      0.66       429\n",
      "\n",
      "    accuracy                           0.71       854\n",
      "   macro avg       0.74      0.71      0.71       854\n",
      "weighted avg       0.74      0.71      0.71       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counter = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "chosenclass = 1\n",
    "for y in y_test:\n",
    "    if y == chosenclass:\n",
    "        total += 1\n",
    "        if y_pred[counter]== y:\n",
    "            correct += 1\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._split.train_test_split(*arrays, **options)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
